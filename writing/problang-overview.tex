\documentclass{sp}

% The \pdf* commands provide metadata for the PDF output.
% Do not use LaTeX style / commands like \emph{} inside these.
\pdfauthor{Author Full Name(s)}
\pdftitle{Full title}
\pdfkeywords{XXX, XXX}

% Optional short title inside square brackets, for the running headers.
% If no short title is given, no title appears in the headers.
%\title[Adjective ordering preferences]{On the grammatical source of adjective ordering preferences%
\title[Practical introduction to RSA]{A practical introduction to the Rational Speech Act modeling framework%
	\thanks{We thank XXX.}}

% Optional short author inside square brackets, for the running headers.
% If no short author is given, no authors print in the headers.
\author[]{% As many authors as you like, each separated by \AND. %%% uncomment to de-anonymize
%	\spauthor{author1 \\ \institute{affiliation1}} \AND
%	\spauthor{author2 \\ \institute{affiliation2}} \AND
%	\spauthor{author3 \\ \institute{affiliation3}}
}

	

\usepackage{linguex}
\usepackage{qtree}
\qtreecenterfalse
\usepackage{tree-dvips}
\usepackage{phonetic}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{lineno}
\usepackage{graphicx}
%\usepackage{qdotbranch}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{CJK}
\usepackage{tikz}
\usepackage{amsfonts} 
\usepackage{amsmath}
\usepackage{hyperref}

\def\url#1{\expandafter\string\csname #1\endcsname}

\newcommand{\gcs}[1]{\textcolor{blue}{[gcs: #1]}}  

\newcommand{\type}[1]{\ensuremath{\left \langle #1 \right \rangle }}
\newcommand{\lam}{\ensuremath{\lambda}}
\newcommand{\sem}[1]{\mbox{$[\![$#1$]\!]$}}

\renewcommand{\firstrefdash}{}

\begin{document}

\maketitle

\begin{abstract}
	Recent advances in computational cognitive science (i.e., simulation-based probabilistic programs) have paved the way for significant progress in formal, implementable models of pragmatics. Rather than describing a pragmatic reasoning process, these models articulate and implement one, deriving both qualitative and quantitative predictions of human behavior---predictions that consistently prove correct, demonstrating the viability and value of the framework. The current paper provides a practical introduction to the Bayesian Rational Speech Act modeling framework, serving as a companion piece to the hands-on web-book at \href{https://www.problang.org}{www.problang.org}. After providing a conceptual overview of the framework, we then walk readers through the resources of the web-book.
\end{abstract}

\begin{keywords}
	XXX, XXX
\end{keywords}

\tableofcontents

\section{Introduction}

Goodies list of RSA

Much work in formal, compositional semantics follows the tradition of positing systematic but inflexible theories of meaning. However, in practice, the meanings we derive from language are heavily dependent on nearly all aspects of context, both linguistic and situational. To formally explain these nuanced aspects of meaning and better understand the compositional mechanism that delivers them, recent work in formal pragmatics recognizes semantics not as one of the final steps in meaning calculation, but rather as one of the first. Within the Bayesian Rational Speech Act (RSA) framework \citep{goodmanfrank2016,frankejaeger2016}, speakers and listeners reason about each other's reasoning about the literal interpretation of utterances. The resulting interpretation necessarily depends on the literal interpretation of an utterance, but is not necessarily wholly determined by it. This move---reasoning about likely interpretations---provides ready explanations for complex phenomena ranging from metaphor \citep{kaoetal2014metaphor} and hyperbole \citep{kaoetal2014} to the specification of thresholds in degree semantics \citep{lassitergoodman2013}.

The probabilistic pragmatics approach leverages the tools of structured probabilistic models formalized in a stochastic $\lambda$-calculus to develop and refine a general theory of communication. The framework synthesizes the knowledge and approaches from diverse areas---formal semantics, Bayesian models of inference, formal theories of measurement, philosophy of language, etc.---into an articulated theory of language in practice. These new tools yield broader empirical coverage and richer explanations for linguistic phenomena through the recognition of language as a means of communication, not merely a vacuum-sealed formal system. By subjecting the heretofore off-limits land of pragmatics to articulated formal models, the rapidly growing body of research both informs pragmatic phenomena and enriches theories of linguistic meaning.

The current paper offers a practical introduction to the modeling framework, serving as a companion piece to the hands-on web-book at \href{https://www.problang.org}{www.problang.org}. We begin in Section \ref{overview} with a high-level overview of RSA, walking through its basic implementation and the philosophical foundations that informed the architectural choices. We then explore variations to the basic architecture in Section \ref{variations}, surveying technological innovations that have allowed for broader empirical coverage. Section \ref{practicalities} discusses common practical considerations faced by the working modeler. In Section \ref{limitations}, we explore limitations of the current framework, which also serve as guidance for future extensions. Section \ref{summary} concludes.


\section{High-level overview of RSA} \label{overview}

The RSA framework views language understanding as a process of recursive social reasoning between speakers and listeners: listeners interpret the utterances they hear by reasoning about how speakers generate them; speakers choose their utterances by reasoning about how listeners interpret them. In the basic, vanilla RSA model from \cite{frankgoodman2012}, this recursion involves three layers of inference. Typically formulated as statements of conditional probability, as in (\ref{L0}--\ref{L1}), these inference layers correspond to models of speakers and listeners.

\begin{equation} \label{L0}
P_{L_0}(s|u) \propto \delta_{[\![u]\!](s)}
\end{equation}
\begin{equation} \label{U}
U_{S_1}(u; s) = \textrm{log}P_{L_0}(s|u) - C(u)
\end{equation}
\begin{equation} \label{S1}
P_{S_1}(u|s) \propto \textrm{exp}(\alpha \cdot U_{S_1}(u;s))
\end{equation}
\begin{equation} \label{L1}
P_{L_1}(s|u) \propto P_{S_1}(u|s) \cdot P(s)
\end{equation}

The reasoning grounds out in the naive, literal listener, $L_0$, who interprets utterances according to their literal semantics. In other words, $L_0$ hears some utterance $u$ and infers the state of the world $s$ that $u$ was meant to describe. $L_0$ performs this inference by restricting the set of possible states to just those that are compatible with the literal, truth-functional semantics of $u$, returning a uniform probability distribution over the states $s$ that $u$ maps to \texttt{true}.

One layer up, a pragmatic speaker, $S_1$, chooses utterances in proportion to their utility $U_{S_{1}}$. Utterances are useful to the extent that they maximize the probability that $L_0$ will infer the correct $s$ on the basis of $u$, while minimizing the cost of $u$ (speakers aim to be efficient). So, when selecting utterances, $S_1$ considers their effect on interpretation (i.e., on $L_0$'s resulting beliefs); utterances that are most likely to lead $L_0$ to the correct belief are most likely to be chosen by $S_1$.

At the top layer of inference, the pragmatic listener, $L_1$, interprets utterances to infer the true state of the world. However, unlike $L_0$, who reasons directly about the utterance semantics, $L_1$ reasons instead about the process that generated the utterance; that process is the speaker $S_1$. $L_1$ thus infers $s$ on the basis of $u$ by reasoning about the probability that $S_1$ would have chosen $u$ to signal $s$ to $L_0$; the higher that probability, the more likely $L_1$ is to conclude that $S_1$ indeed intended to communicate $s$. Because $L_1$ reasons about $S_1$, who in turn reasons about the literal semantics in $L_0$, $L_1$'s interpretation is affected by the semantics of $u$, albeit only indirectly via the $S_1$ layer. This space between the semantics (i.e., $L_0$) and the resulting interpretation (i.e., the posterior beliefs of $L_1$) is where pragmatics enters. To see how, it would help to consider a concrete communication scenario.

In its initial formulation, \cite{frankgoodman2012} use the RSA framework to model referent choices in efficient communication. Suppose we are in a world as in Figure \ref{ref-game} with three objects: a blue square, a blue circle, and a green square. Suppose further that a speaker is trying to signal a single object in this world to a cooperative listener, and that the speaker can only use a single-word utterance to do so. The utterances available to the speaker include ``blue'', ``green'', ``square'', and ``circle''; the possible states the listener might infer correspond to the three objects: blue-square, blue-circle, and green-square. We have the expected truth-functional semantics for the utterances: ``blue'' maps blue-square and blue-circle to true but green-square to false, ``green'' maps blue-square and blue-circle to false but green-square to true, etc.

\begin{figure}[t]
\includegraphics[width=3in]{rsa-scene.pdf}
\caption{An example referential-communication game from \cite{frankgoodman2012}.}
\label{ref-game}
\end{figure}

With the semantics as stated, $L_0$ interprets utterances to return uniform probability distributions over the compatible states. Hearing the utterance ``blue'', $L_0$ returns a belief distribution over states that divides probability equally between blue-square and blue-circle, the only objects compatible with the semantics of ``blue''. Hearing ``circle'', $L_0$ returns a distribution with 100\% of the probability on blue-circle---$L_0$ is certain that the speaker intends to signal blue-circle. At this point we have an agent who interprets utterances naively, according to the literal semantics. 

$S_0$ chooses utterances by simulating their effect on $L_0$. Suppose the speaker wants to communicate blue-circle to $L_0$. Two utterances, ``green'' and ``square'', stand no chance of communicating the intended state to $L_0$ and so they are ruled out. The other two utterances, ``blue'' and ``circle'', are both literally compatible with blue-circle, but one of the utterances is more likely to lead $L_0$ to the correct belief state. If the speaker were to utter ``blue'', we saw that $L_0$'s belief distribution would be evenly split between blue-square and blue-circle. In other words, ``blue'' has a 50\% chance of leading $L_0$ to the correct state. On the other hand, ``circle'' has a 100\% chance of leading $L_0$ to the correct state. Assuming equal utterance costs, ``circle'' is thus twice as useful to the speaker as ``blue'' for communicating blue-circle to $L_0$, and $S_1$ reflects this asymmetry in utility by assigning twice as much probability to ``circle'' in the posterior distribution over utterance choices.\footnote{With no scaling. XXX} For communicating the blue-square state, both ``blue'' and ``square'' have a 50\% chance of leading $L_0$ to the correct state, so both utterances are equally likely and thus equally probable in the $S_1$ posterior.

Within this simple reference-game scenario, $L_1$ reasons pragmatically about $S_1$ to break the symmetry in the semantics. Hearing ``blue'', $L_1$ will invert the $S_1$ model to determine which state (i.e., which object) the speaker is most likely trying to communicate. Had the speaker wanted to communicate the blue-circle state, we saw above that the speaker would have been more likely to utter ``circle''. But the speaker did not utter ``circle''; she uttered ``blue'' instead. This hypothetical reasoning leads $L_1$ to down-weight the probability of the state that ``circle'' could have uniquely picked out, since the speaker could have said ``circle'' but chose not to. As a result, more probably gets assigned to the blue-square state, the other state compatible with the semantics of the utterance. In this way, we capture the Gricean specificity implicature associated with uttering ``blue'' in a scenario as in Figure \ref{ref-game}: the speaker probably intends the blue square because if she wanted to communicate the blue circle she could have said ``circle''.

MF's math (derivable from KL, connection to Grice maxims)

\section{Variations on vanilla} \label{variations}

\subsection{Lexical inference type models}

write like this, useful for this, have the following goodies..

\subsection{QUD inference}

\subsection{Context/Prior inference}

\subsection{Epistemic inference}

\subsection{Complex utility/utilty inference}

\section{Modeling practicalities} \label{practicalities}

Free parameters (optimality, cost, alternatives)

World priors: Both how to model and how to measure

QUD

Linking functions

\section{Extensions/limitations} \label{limitations}

Incrementality / processing

Compositionality (CCG chapter in dippl?)

NLP (Dan Klein)

Individual variability (cite Franke \& Degen)

``Just'' a computational level theory. Doesn't bear on mechanisms. But, potentially a hook via resource rational analysis (Leider, Griffiths, ...)

Hand-coded: Don't have a theory of alternatives, state priors

\section{Summary and outlook} \label{summary}

XXX


\bibliography{problang}

%\begin{addresses} %%% uncomment to de-anonymize
%	\begin{address}
%		author1
%		\email{email1}
%	\end{address}
%	\begin{address}
%		author2
%		\email{email2}
%	\end{address}
%	\begin{address}
%		author3
%		\email{email3}
%	\end{address}
%\end{addresses}



\end{document}
